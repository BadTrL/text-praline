{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc5a64c4",
   "metadata": {},
   "source": [
    "Test RAG raw vs Praline\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d84d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/badtroll/Library/Caches/pypoetry/virtualenvs/textpraline-BxvUXBda-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 1410.86it/s, Materializing param=pooler.dense.weight]                               \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: BAAI/bge-base-en-v1.5\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed RAW:     docs=5, chunks=1238\n",
      "Indexed PRALINE: docs=5, chunks=1221\n",
      "\n",
      "==============================\n",
      "FULL QUESTION DEBUG\n",
      "==============================\n",
      "\n",
      "-----------------------------------\n",
      "Question: What is the splashback radius studied with?\n",
      "Expected doc: docu_astro\n",
      "\n",
      "RAW:\n",
      "\n",
      "Q: What is the splashback radius studied with?\n",
      "1. dist=0.1736 doc_id=docu_astro chunk=41\n",
      "    y Duffy et al. (2008). 4.5. Splashback radius estimator The main goal of this study consists in constraining the following relation (introduced by More et al. 2015): ⟨Rsp(∆λ∗ ob, ∆zob)⟩= Asp \" 1 + Bsp exp   −⟨ν200m(∆λ∗ ob, ∆zob)⟩ 2.44 !# , (33) where Asp and B…\n",
      "2. dist=0.2292 doc_id=docu_astro chunk=7\n",
      "    n 2023), which is about 2 times larger than rsp and corresponds to the scale above which the matter density decreases with time. Pizzardo et al. (2024) demonstrated that the inflection point in the radial velocity pro- file of cluster galaxies agrees with rsp …\n",
      "3. dist=0.2580 doc_id=docu_astro chunk=1\n",
      "    etti 101, 40129 Bologna, Italy 8 Ruhr University Bochum, Faculty of Physics and Astronomy, Astronomical Institute (AIRUB), German Centre for Cosmological Lensing, 44780 Bochum, Germany 9 INAF - Osservatorio Astronomico di Capodimonte, Salita Moiariello 16, Nap…\n",
      "4. dist=0.2703 doc_id=docu_astro chunk=4\n",
      "    reno et al. 2018; Giocoli et al. 2021; Ingoglia et al. 2022; Eltvedt et al. 2024). In the transition between the virialised region and the two- halo regime, a sharp steepening in the density profile is expected. This feature, located in the proximity of the sp…\n",
      "5. dist=0.2783 doc_id=docu_astro chunk=87\n",
      "    es derived from the gt modelling presented in this work (based on Eq. 54 in L25) and those from L25. De- spite L25 adopting the truncated NFW profile by Baltz, Mar- shall, & Oguri (2009, BMO) rather than the DK14 profile in Eq. (8), and modelling the gt profil…\n",
      "\n",
      "PRALINE:\n",
      "\n",
      "Q: What is the splashback radius studied with?\n",
      "1. dist=0.1874 doc_id=docu_astro chunk=40\n",
      "    (2008). 4.5. Splashback radius estimator The main goal of this study consists in constraining the following relation (introduced by More et al. 2015): ⟨Rsp(∆λ∗ ob, ∆zob)⟩= Asp \" 1 + Bsp exp  −⟨ν200m(∆λ∗ 2.44 !# (33) where Asp and Bsp are free parameters, while…\n",
      "2. dist=0.2430 doc_id=docu_astro chunk=7\n",
      "    ove which the matter density decreases with time. Pizzardo et al. (2024) demonstrated that the inflection point in the radial velocity pro- file of cluster galaxies agrees with rsp within 1σ, establishing an additional connection between the splashback radius …\n",
      "3. dist=0.2464 doc_id=docu_astro chunk=57\n",
      "    is a stronger probe of the splashback radius, as it directly con- strains the infalling term parameters, which are not accessible via weak-lensing observations (see Appendix D). The right panels of Fig. 3 show that rsp estimates from wcg are systematically low…\n",
      "4. dist=0.2590 doc_id=docu_astro chunk=1\n",
      "    etti 101, 40129 Bologna, Italy 8 Ruhr University Bochum, Faculty of Physics and Astronomy, Astronomical Institute (AIRUB), German Centre for Cosmological Lensing, 44780 Bochum, Germany 9 INAF - Osservatorio Astronomico di Capodimonte, Salita Moiariello 16, Nap…\n",
      "5. dist=0.2699 doc_id=docu_astro chunk=4\n",
      "    reno et al. 2018; Giocoli et al. 2021; Ingoglia et al. 2022; Eltvedt et al. 2024). In the transition between the virialised region and the two- halo regime, a sharp steepening in the density profile is expected. This feature, located in the proximity of the sp…\n",
      "\n",
      "-----------------------------------\n",
      "Question: What does PEP 8 recommend about line length?\n",
      "Expected doc: pep8\n",
      "\n",
      "RAW:\n",
      "\n",
      "Q: What does PEP 8 recommend about line length?\n",
      "1. dist=0.2502 doc_id=pep8 chunk=8\n",
      "    xample: [pep8] ignore = E226,E302,E41 max-line-length = 160 At the project level, a setup.cfg ﬁle or a tox.ini ﬁle is read if present (.pep8 ﬁle is also supported, but it is deprecated). If none of these ﬁles have a [pep8] section, no project speciﬁc conﬁgurat…\n",
      "2. dist=0.2614 doc_id=pep8 chunk=14\n",
      "    expected, line_offset=line_offset) if __name__ == '__main__': pep8style = PEP8(parse_argv=True, config_file=True) report = pep8style.check_files() if report.total_errors: raise SystemExit(1) This module declares a lines’ window which skips 14 lines at the begi…\n",
      "3. dist=0.2911 doc_id=pep8 chunk=31\n",
      "    7) 4.4. Changes 21  pep8 documentation, Release 1.7.1.dev0 • Fix AssertionError when the source ﬁle contains an invalid line ending \"\\r\\r\\n\". (Issue #119) • Read the [pep8] section of tox.ini or setup.cfg if present. (Issue #93 and #141) • Add the Sphinx-based…\n",
      "4. dist=0.2954 doc_id=pep8 chunk=19\n",
      "    Using the ast module defeats that purpose. The pep8-naming plugin exists for this sort of functionality. • If you want to provide extensibility / plugins, please see ﬂake8 - pep8 doesn’t want or need a plugin architecture. • Python 2.6 support is still deemed …\n",
      "5. dist=0.3014 doc_id=pep8 chunk=6\n",
      "    help is available on the command line: $ pep8 -h Usage: pep8 [options] input ... Options: --version show program's version number and exit -h, --help show this help message and exit -v, --verbose print status messages, or debug with -vv -q, --quiet report only…\n",
      "\n",
      "PRALINE:\n",
      "\n",
      "Q: What does PEP 8 recommend about line length?\n",
      "1. dist=0.2507 doc_id=pep8 chunk=19\n",
      "    irections to bear in mind for contributions: • pep8 is intended to be as fast as possible. Using the ast module defeats that purpose. The pep8-naming plugin exists for this sort of functionality. • If you want to provide extensibility / plugins, please see fla…\n",
      "2. dist=0.2606 doc_id=pep8 chunk=8\n",
      "    not defined: ~/.config/pep8 Example: [pep8] ignore = E226,E302,E41 max-line-length = 160 At the project level, a setup.cfg file or a tox.ini file is read if present (.pep8 file is also supported, but it is deprecated). If none of these files have a [pep8] sect…\n",
      "3. dist=0.2632 doc_id=pep8 chunk=31\n",
      "    ement\". (Issue #96) • Lines with a # nopep8 at the end will not issue errors on line length E501 or continuation line indentation E12*. (Issue #27) 4.4. Changes 21  pep8 documentation, Release 1.7.1.dev0 • Fix AssertionError when the source file contains an in…\n",
      "4. dist=0.2894 doc_id=pep8 chunk=25\n",
      "    a physical line. (Issue #268) 18 Chapter 4. Developer's notes  pep8 documentation, Release 1.7.1.dev0 4.4.10 1.5.2 (2014-04-04) Changes: • Distribute a universal wheel file. Bug fixes: • Report correct line number for E303 with comments. (Issue #60) • Do not a…\n",
      "5. dist=0.2925 doc_id=pep8 chunk=6\n",
      "    t Quick help is available on the command line: $ pep8 -h Usage: pep8 [options] input ... Options: • -version show program's version number and exit • h, --help show this help message and exit • v, --verbose print status messages, or debug with -vv • q, --quiet…\n",
      "\n",
      "-----------------------------------\n",
      "Question: What are ESG priorities discussed in the report?\n",
      "Expected doc: Morgan_Stanley_2023_ESG_Report\n",
      "\n",
      "RAW:\n",
      "\n",
      "Q: What are ESG priorities discussed in the report?\n",
      "1. dist=0.2402 doc_id=Morgan_Stanley_2023_ESG_Report chunk=8\n",
      "    APPENDICES  About This Report 3 The Morgan Stanley ESG Report provides an annual overview of the firm’s approach to and performance on environmental,   social and governance (ESG) topics.  The Glasgow Financial Alliance for Net Zero (GFANZ)  transition plannin…\n",
      "2. dist=0.2502 doc_id=Morgan_Stanley_2023_ESG_Report chunk=15\n",
      "    but to the environment and society  at large. In order to do this, we need to ensure  that relevant ESG topics are incorporated into our  corporate policies, business activities and operations.  There are various ESG topics that are important to  the firm, wit…\n",
      "3. dist=0.2605 doc_id=Morgan_Stanley_2023_ESG_Report chunk=236\n",
      "    of the  information included in the 2023 ESG Report and  for the selection of the criteria, which management  believes provide an objective basis for measuring  and reporting on the subject matter. Management of  Morgan Stanley asserts that the subject matter …\n",
      "4. dist=0.2606 doc_id=Morgan_Stanley_2023_ESG_Report chunk=210\n",
      "    es and priorities in its core evaluation and decision-making  tools and processes to support its net-zero commitment. •\t \u0007This applies to both top-down/oversight structures and bottom-up tools and actions. •\t ESG Governance •\t Climate Risk Management  Policies…\n",
      "5. dist=0.2631 doc_id=Morgan_Stanley_2023_ESG_Report chunk=0\n",
      "    2023 ESG Report  TABLE OF CONTENTS  3 From Our CEO  4 Introduction 4\t Our Business 5\t About This Report 6\t Our Approach to ESG 7\t \u00072023 ESG Highlights  8 Sustainable Finance 8\t Sustainable Finance Target 11\t Institutional Securities 15\t Wealth Management 20\t I…\n",
      "\n",
      "PRALINE:\n",
      "\n",
      "Q: What are ESG priorities discussed in the report?\n",
      "1. dist=0.2436 doc_id=Morgan_Stanley_2023_ESG_Report chunk=162\n",
      "    on environmental and social topics. We review our policies annually and update them as necessary to reflect our strategy and key developments. As a result of this year's review of the Environmental and Social Policy Statement, we have revised our due diligence…\n",
      "2. dist=0.2519 doc_id=Morgan_Stanley_2023_ESG_Report chunk=233\n",
      "    f the efforts set forth in this report. Any forward-looking statements made by or on behalf of Morgan Stanley speak only as to the date they are made, and Morgan Stanley does not undertake to update forward-looking statements to reflect the impact of circumsta…\n",
      "3. dist=0.2586 doc_id=Morgan_Stanley_2023_ESG_Report chunk=0\n",
      "    2023 ESG Report  TABLE OF CONTENTS  3 From Our CEO  4 Introduction 4 Our Business 5 About This Report 6 Our Approach to ESG 7 2023 ESG Highlights  8 Sustainable Finance 8 Sustainable Finance Target 11 Institutional Securities 15 Wealth Management 20 Investment…\n",
      "4. dist=0.2602 doc_id=Morgan_Stanley_2023_ESG_Report chunk=8\n",
      "    Disclosure Committee, composed of senior leaders from across the firm, provides input on, reviews and approves this report. In this report, Morgan Stanley uses the terms \"ESG\" and \"sustainability\" interchangeably. Throughout this report, we also refer to both …\n",
      "5. dist=0.2805 doc_id=Morgan_Stanley_2023_ESG_Report chunk=75\n",
      "    dual performance in light of these preestablished performance priorities. Performance priorities that relate to ESG focus areas include culture, leadership, reputation, workforce resilience and diversity. The Board's CMDS Committee is also committed to driving…\n",
      "\n",
      "-----------------------------------\n",
      "Question: What are the main risks mentioned in the IMF report?\n",
      "Expected doc: imf_report\n",
      "\n",
      "RAW:\n",
      "\n",
      "Q: What are the main risks mentioned in the IMF report?\n",
      "1. dist=0.2959 doc_id=imf_report chunk=339\n",
      "    the  Precautionary and Liquidity Line, and Proposals for Reform.”  IMF Policy Paper 2023/039, International Monetary Fund,  Washington, DC. Ioannidou, V., S. Kokas, T. Lambert, and A. Michaelides.  2025. “(In)dependent Central Banks.” SSRN Working Paper  42626…\n",
      "2. dist=0.3066 doc_id=imf_report chunk=157\n",
      "    O) baseline forecast and the  IMF’s Global Integrated Monetary and Fiscal (GIMF)  model to analyze shocks that could materialize over  the five-year WEO horizon. While the risk scenarios  presented in the April 2025 WEO remain relevant,  two new scenarios are …\n",
      "3. dist=0.3131 doc_id=imf_report chunk=21\n",
      "    ook are integral elements of the IMF’s  surveillance of economic developments and policies in its member countries, of developments in international  financial markets, and of the global economic system. The survey of prospects and policies is the product of a…\n",
      "4. dist=0.3133 doc_id=imf_report chunk=230\n",
      "    International Labour Organization (ILO). 2025. “Global  Estimates on International Migrants in the Labour Force.”  Geneva. International Monetary Fund (IMF). 2025a. “Debt  Vulnerabilities and Financing Challenges in Emerging  Markets and Developing Economies—A…\n",
      "5. dist=0.3177 doc_id=imf_report chunk=224\n",
      "    C OUTLOOK: Global Economy in Flux, Prospects Remain Dim 48 International Monetary Fund | October 2025 References Acalin, Julien, Virginia Alonso, Clara Arroyo, W. Raphael Lam,  Leonardo Martinez, Anh Dinh Minh Nguyen, Francisco  Roch, Galen Sher, and Alexandra…\n",
      "\n",
      "PRALINE:\n",
      "\n",
      "Q: What are the main risks mentioned in the IMF report?\n",
      "1. dist=0.3229 doc_id=imf_report chunk=23\n",
      "    for the report, with production and editorial support from Michael Harrup, Kristina Harwood, Lucy Scott Morales, James Unwin, MPS Limited, and Absolute Service, Inc. The analysis has benefited from comments and suggestions by staff members from other IMF depar…\n",
      "2. dist=0.3260 doc_id=imf_report chunk=18\n",
      "    l editions of the WEO, including ePub, enhanced PDF, and HTML, are available on the IMF eLibrary at eLibrary.IMF.org/WEO. Download a free PDF of the report and data sets for each of the charts therein from the IMF website at www.IMF.org/publications/weo or sca…\n",
      "3. dist=0.3269 doc_id=imf_report chunk=11\n",
      "    .2. Dates and Features of Risk-Off Episodes 56 Figure 2.3. Effects of Risk-Off Shocks 56 Figure 2.4. Monetary Policy Reaction Function 57 Figure 2.5. Central Bank Independence and Autonomy 58 Figure 2.6. Use of Foreign Exchange Interventions in Response to Unc…\n",
      "4. dist=0.3299 doc_id=imf_report chunk=644\n",
      "    ould further reduce fiscal space, challenging efforts to rebuild fiscal buffers and making bond market functioning more fragile. Directors also acknowledged that stretched risk asset valuations and higher interconnectedness between banks and nonbank financial …\n",
      "5. dist=0.3299 doc_id=imf_report chunk=227\n",
      "    : How Trade Policy Is Reshaping Multinational Firms' Location.\" CESifo Working Paper Series. Huckstep, Sam, Laura Granito, Sara Casadevall Bellés, and Lee Crawfurd. 2025. \"Charting the Fallout of Aid Cuts: Which Countries Will Be Hit Hardest, as Multiple Donor…\n",
      "\n",
      "-----------------------------------\n",
      "Question: What is discussed about large language models?\n",
      "Expected doc: llm_pdf\n",
      "\n",
      "RAW:\n",
      "\n",
      "Q: What is discussed about large language models?\n",
      "1. dist=0.1671 doc_id=llm_pdf chunk=0\n",
      "    Large Language Models: A Survey Shervin Minaee1, Tomas Mikolov2, Narjes Nikzad3, Meysam Chenaghlu4 Richard Socher5, Xavier Amatriain6, Jianfeng Gao7 1 Applied Scientist, Amazon Inc 2 Senior Researcher, CIIRC CTU 3 Cologne University of Applied Sciences 4 Staff…\n",
      "2. dist=0.1975 doc_id=llm_pdf chunk=1\n",
      "    tributions and limitations. We also give an overview of techniques developed to build, and augment LLMs. We then survey popular datasets prepared for LLM training, fine-tuning, and evaluation, review widely used LLM evaluation metrics, and compare the performa…\n",
      "3. dist=0.2144 doc_id=llm_pdf chunk=138\n",
      "    rds ”larger is better” that has clearly been rewarded with ever larger models like GPT- 4 getting better accuracy and performance in benchmarks. However, those large models are costly and inefficient in several dimensions (e.g. high latency). In response to al…\n",
      "4. dist=0.2177 doc_id=llm_pdf chunk=40\n",
      "    investigated the optimal model size and number of tokens for training a transformer language model under a given compute budget. By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, they found t…\n",
      "5. dist=0.2196 doc_id=llm_pdf chunk=163\n",
      "    trained transformer language models,” arXiv preprint arXiv:2205.01068, 2022. [87] R. Taylor, M. Kardas, G. Cucurull, T. Scialom, A. Hartshorn, E. Sar- avia, A. Poulton, V. Kerkez, and R. Stojnic, “Galactica: A large language model for science,” arXiv preprint …\n",
      "\n",
      "PRALINE:\n",
      "\n",
      "Q: What is discussed about large language models?\n",
      "1. dist=0.1612 doc_id=llm_pdf chunk=0\n",
      "    Large Language Models: A Survey Shervin Minaee1, Tomas Mikolov2, Narjes Nikzad3, Meysam Chenaghlu4 Richard Socher5, Xavier Amatriain6, Jianfeng Gao7 1 Applied Scientist, Amazon Inc 2 Senior Researcher, CIIRC CTU 3 Cologne University of Applied Sciences 4 Staff…\n",
      "2. dist=0.1969 doc_id=llm_pdf chunk=1\n",
      "    tributions and limitations. We also give an overview of techniques developed to build, and augment LLMs. We then survey popular datasets prepared for LLM training, fine-tuning, and evaluation, review widely used LLM evaluation metrics, and compare the performa…\n",
      "3. dist=0.2107 doc_id=llm_pdf chunk=162\n",
      "    107.02137, 2021. [82] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Mil- lican, G. B. Van Den Driessche, J.-B. Lespiau, B. Damoc, A. Clark et al., \"Improving language models by retrieving from trillions of tokens,\" in International conference …\n",
      "4. dist=0.2200 doc_id=llm_pdf chunk=147\n",
      "    ), then review three popular LLM families (GPT, LLaMA, PaLM), and other representative LLMs. We then survey methods and techniques of building, augmenting, and using LLMs. We review popular LLM datasets and benchmarks, and compare performance of a set of promi…\n",
      "5. dist=0.2245 doc_id=llm_pdf chunk=36\n",
      "    m models with tens of millions of parameters up to a 280 billion parameter model called Gopher. These models were evaluated on 152 diverse tasks, achieving state-of-the-art performance across the majority. The number of layers, the key/value size, and other hy…\n",
      "\n",
      "--- RAW ---\n",
      "What is the splashback radius studied with? : {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}\n",
      "What does PEP 8 recommend about line length? : {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}\n",
      "What are ESG priorities discussed in the report? : {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}\n",
      "What are the main risks mentioned in the IMF report? : {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}\n",
      "What is discussed about large language models? : {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}\n",
      "__global__ : {'recall@1': 1.0, 'recall@5': 1.0, 'recall@10': 1.0, 'mrr': 1.0}\n",
      "\n",
      "--- PRALINE ---\n",
      "What is the splashback radius studied with? : {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}\n",
      "What does PEP 8 recommend about line length? : {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}\n",
      "What are ESG priorities discussed in the report? : {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}\n",
      "What are the main risks mentioned in the IMF report? : {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}\n",
      "What is discussed about large language models? : {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}\n",
      "__global__ : {'recall@1': 1.0, 'recall@5': 1.0, 'recall@10': 1.0, 'mrr': 1.0}\n",
      "\n",
      "--- Summary (doc-level) ---\n",
      "RAW    : {'What is the splashback radius studied with?': {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}, 'What does PEP 8 recommend about line length?': {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}, 'What are ESG priorities discussed in the report?': {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}, 'What are the main risks mentioned in the IMF report?': {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}, 'What is discussed about large language models?': {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}, '__global__': {'recall@1': 1.0, 'recall@5': 1.0, 'recall@10': 1.0, 'mrr': 1.0}}\n",
      "PRALINE: {'What is the splashback radius studied with?': {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}, 'What does PEP 8 recommend about line length?': {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}, 'What are ESG priorities discussed in the report?': {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}, 'What are the main risks mentioned in the IMF report?': {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}, 'What is discussed about large language models?': {'recall@1': 1, 'recall@5': 1, 'recall@10': 1, 'mrr': 1.0}, '__global__': {'recall@1': 1.0, 'recall@5': 1.0, 'recall@10': 1.0, 'mrr': 1.0}}\n",
      "\n",
      "==============================\n",
      "PRALINE REPORTS\n",
      "==============================\n",
      "\n",
      "Document: Morgan_Stanley_2023_ESG_Report\n",
      "PralineReport(input_len=263440, output_len=250901, removed_toc_lines=0, normalized_extracted=False, removed_layout_noise_lines=0, removed_repeated_lines=0, removed_boilerplate_lines=0)\n",
      "\n",
      "Document: docu_astro\n",
      "PralineReport(input_len=96072, output_len=92885, removed_toc_lines=0, normalized_extracted=True, removed_layout_noise_lines=22, removed_repeated_lines=425, removed_boilerplate_lines=31)\n",
      "\n",
      "Document: imf_report\n",
      "PralineReport(input_len=685781, output_len=682507, removed_toc_lines=0, normalized_extracted=False, removed_layout_noise_lines=0, removed_repeated_lines=0, removed_boilerplate_lines=0)\n",
      "\n",
      "Document: llm_pdf\n",
      "PralineReport(input_len=209059, output_len=209064, removed_toc_lines=0, normalized_extracted=False, removed_layout_noise_lines=0, removed_repeated_lines=0, removed_boilerplate_lines=0)\n",
      "\n",
      "Document: pep8\n",
      "PralineReport(input_len=43965, output_len=44145, removed_toc_lines=0, normalized_extracted=False, removed_layout_noise_lines=0, removed_repeated_lines=0, removed_boilerplate_lines=0)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "import fitz\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from textpraline.cleaner.clean import praline, PralineReport\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Config\n",
    "# =============================================================================\n",
    "\n",
    "CORPUS_DIR = Path(\"./corpus\")  # .txt files recommended for now\n",
    "\n",
    "MODEL_NAME = \"BAAI/bge-base-en-v1.5\"  # or \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "TOP_KS = (1, 5, 10)\n",
    "\n",
    "CHUNK_SIZE = 1200\n",
    "CHUNK_OVERLAP = 150\n",
    "\n",
    "COL_RAW = \"docs_raw\"\n",
    "COL_PRALINE = \"docs_praline\"\n",
    "\n",
    "# Optional: remove academic boilerplate that hurts retrieval (generic, safe-ish)\n",
    "DROP_LINE_PATTERNS = [\n",
    "    re.compile(r\"^\\s*send offprint requests to\\s*:\\s*.*$\", re.IGNORECASE),\n",
    "    re.compile(r\"^\\s*article number,\\s*page\\s*\\d+\\s*of\\s*\\d+.*$\", re.IGNORECASE),\n",
    "]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset format\n",
    "# =============================================================================\n",
    "\n",
    "# Start simple: list of (question, expected_doc_id)\n",
    "EVAL: List[Tuple[str, str]] = [\n",
    "    (\"What is the splashback radius studied with?\", \"docu_astro\"),\n",
    "    (\"What does PEP 8 recommend about line length?\", \"pep8\"),\n",
    "    (\"What are ESG priorities discussed in the report?\", \"Morgan_Stanley_2023_ESG_Report\"),\n",
    "    (\"What are the main risks mentioned in the IMF report?\", \"imf_report\"),\n",
    "    (\"What is discussed about large language models?\", \"llm_pdf\"),\n",
    "]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Helpers\n",
    "# =============================================================================\n",
    "\n",
    "def load_pdf_corpus(corpus_dir: Path) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Returns list of (doc_id, extracted_text).\n",
    "    \"\"\"\n",
    "    items = []\n",
    "\n",
    "    for p in sorted(corpus_dir.glob(\"*.pdf\")):\n",
    "        doc_id = p.stem\n",
    "        doc = fitz.open(p)\n",
    "        text = \"\"\n",
    "\n",
    "        for page in doc:\n",
    "            text += page.get_text(\"text\") + \"\\n\"\n",
    "\n",
    "        items.append((doc_id, text))\n",
    "\n",
    "    if not items:\n",
    "        raise RuntimeError(f\"No .pdf files found in {corpus_dir.resolve()}\")\n",
    "\n",
    "    return items\n",
    "\n",
    "\n",
    "def drop_lines(text: str, patterns: Iterable[re.Pattern]) -> str:\n",
    "    \"\"\"\n",
    "    Remove lines matching any of the given regex patterns.\n",
    "    \"\"\"\n",
    "    out: List[str] = []\n",
    "    for ln in text.splitlines():\n",
    "        if any(p.match(ln.strip()) for p in patterns):\n",
    "            continue\n",
    "        out.append(ln)\n",
    "    return \"\\n\".join(out)\n",
    "\n",
    "def chunk_text(text: str, *, chunk_size: int, chunk_overlap: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Deterministic character-based chunking with overlap.\n",
    "    \"\"\"\n",
    "    if chunk_size <= 0:\n",
    "        raise ValueError(\"chunk_size must be > 0\")\n",
    "    if chunk_overlap < 0:\n",
    "        raise ValueError(\"chunk_overlap must be >= 0\")\n",
    "    if chunk_overlap >= chunk_size:\n",
    "        raise ValueError(\"chunk_overlap must be < chunk_size\")\n",
    "\n",
    "    chunks: List[str] = []\n",
    "    step = chunk_size - chunk_overlap\n",
    "    n = len(text)\n",
    "\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        chunks.append(text[i : i + chunk_size])\n",
    "        i += step\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "\n",
    "def build_collection(\n",
    "    client: chromadb.ClientAPI,\n",
    "    name: str,\n",
    "    embed_fn: SentenceTransformerEmbeddingFunction,\n",
    "    docs: List[Tuple[str, str]],\n",
    "    *,\n",
    "    apply_praline: bool,\n",
    "    chunk_size: int,\n",
    "    chunk_overlap: int,\n",
    ") -> Tuple[int, Dict[str, Optional[PralineReport]]]:\n",
    "    \"\"\"\n",
    "    Create/recreate a collection and index all documents as chunks.\n",
    "\n",
    "    Returns:\n",
    "      - chunks_added (int)\n",
    "      - per_doc_reports: Dict[doc_id, PralineReport|None]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.delete_collection(name)\n",
    "    except Exception:\n",
    "        pass\n",
    "    col = client.get_or_create_collection(name=name, embedding_function=embed_fn)\n",
    "\n",
    "    ids: List[str] = []\n",
    "    texts: List[str] = []\n",
    "    metas: List[Dict[str, object]] = []\n",
    "\n",
    "    per_doc_reports: Dict[str, Optional[PralineReport]] = {}\n",
    "    chunk_count = 0\n",
    "\n",
    "    for doc_id, raw in docs:\n",
    "        if apply_praline:\n",
    "            txt, rep = praline(raw, debug=True)  # (cleaned, report)\n",
    "            per_doc_reports[doc_id] = rep\n",
    "        else:\n",
    "            txt = raw\n",
    "            per_doc_reports[doc_id] = None\n",
    "\n",
    "        txt = drop_lines(txt, DROP_LINE_PATTERNS)\n",
    "\n",
    "        chunks = chunk_text(txt, chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "        for idx, ch in enumerate(chunks):\n",
    "            ch = ch.strip()\n",
    "            if len(ch) < 40:\n",
    "                continue\n",
    "            ids.append(f\"{doc_id}__{idx:05d}\")\n",
    "            texts.append(ch)\n",
    "            metas.append({\"doc_id\": doc_id, \"chunk_idx\": idx})\n",
    "            chunk_count += 1\n",
    "\n",
    "    col.add(ids=ids, documents=texts, metadatas=metas)\n",
    "    return chunk_count, per_doc_reports\n",
    "\n",
    "\n",
    "def query_doc_ids(\n",
    "    col,\n",
    "    question: str,\n",
    "    *,\n",
    "    top_k: int,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Return doc_id list for the top_k retrieved chunks.\n",
    "    \"\"\"\n",
    "    res = col.query(\n",
    "        query_texts=[question],\n",
    "        n_results=top_k,\n",
    "        include=[\"metadatas\"],\n",
    "    )\n",
    "    metas = res[\"metadatas\"][0]\n",
    "    return [m[\"doc_id\"] for m in metas]\n",
    "\n",
    "\n",
    "def query_debug(col, question: str, *, top_k: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Print top_k chunks with distances + snippets (for observability).\n",
    "    \"\"\"\n",
    "    res = col.query(\n",
    "        query_texts=[question],\n",
    "        n_results=top_k,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"],\n",
    "    )\n",
    "    docs = res[\"documents\"][0]\n",
    "    metas = res[\"metadatas\"][0]\n",
    "    dists = res[\"distances\"][0]\n",
    "\n",
    "    print(\"\\nQ:\", question)\n",
    "    for i, (txt, m, dist) in enumerate(zip(docs, metas, dists), 1):\n",
    "        snippet = (txt[:260] + \"…\").replace(\"\\n\", \" \")\n",
    "        print(f\"{i}. dist={dist:.4f} doc_id={m['doc_id']} chunk={m['chunk_idx']}\")\n",
    "        print(\"   \", snippet)\n",
    "\n",
    "\n",
    "def recall_at_k(retrieved_doc_ids: List[str], expected_doc_id: str) -> int:\n",
    "    return int(expected_doc_id in retrieved_doc_ids)\n",
    "\n",
    "\n",
    "def reciprocal_rank(retrieved_doc_ids: List[str], expected_doc_id: str) -> float:\n",
    "    for i, doc_id in enumerate(retrieved_doc_ids, start=1):\n",
    "        if doc_id == expected_doc_id:\n",
    "            return 1.0 / i\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    col,\n",
    "    eval_set: List[Tuple[str, str]],\n",
    "    ks: Tuple[int, ...],\n",
    ") -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Multi-doc evaluation:\n",
    "    - Recall@k\n",
    "    - MRR\n",
    "    - Per-document breakdown\n",
    "    \"\"\"\n",
    "    max_k = max(ks)\n",
    "\n",
    "    results = {}\n",
    "    global_recall = {k: 0 for k in ks}\n",
    "    global_rr = 0.0\n",
    "\n",
    "    for q, expected_doc in eval_set:\n",
    "        retrieved = query_doc_ids(col, q, top_k=max_k)\n",
    "\n",
    "        doc_metrics = {}\n",
    "        for k in ks:\n",
    "            hit = recall_at_k(retrieved[:k], expected_doc)\n",
    "            global_recall[k] += hit\n",
    "            doc_metrics[f\"recall@{k}\"] = hit\n",
    "\n",
    "        rr = reciprocal_rank(retrieved, expected_doc)\n",
    "        global_rr += rr\n",
    "        doc_metrics[\"mrr\"] = rr\n",
    "\n",
    "        results[q] = doc_metrics\n",
    "\n",
    "    n = len(eval_set)\n",
    "\n",
    "    results[\"__global__\"] = {\n",
    "        **{f\"recall@{k}\": global_recall[k] / n for k in ks},\n",
    "        \"mrr\": global_rr / n,\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Main\n",
    "# =============================================================================\n",
    "\n",
    "def main() -> None:\n",
    "    docs = load_pdf_corpus(CORPUS_DIR)\n",
    "\n",
    "    # In-memory Chroma for fast iteration\n",
    "    client = chromadb.Client()\n",
    "\n",
    "    # Local embeddings\n",
    "    embed_fn = SentenceTransformerEmbeddingFunction(model_name=MODEL_NAME)\n",
    "\n",
    "\n",
    "    chunks_raw, _ = build_collection(\n",
    "        client,\n",
    "        COL_RAW,\n",
    "        embed_fn,\n",
    "        docs,\n",
    "        apply_praline=False,\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "    )\n",
    "\n",
    "    chunks_prl, praline_reports = build_collection(\n",
    "        client,\n",
    "        COL_PRALINE,\n",
    "        embed_fn,\n",
    "        docs,\n",
    "        apply_praline=True,\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP,\n",
    "    )\n",
    "\n",
    "    col_raw = client.get_collection(COL_RAW, embedding_function=embed_fn)\n",
    "    col_prl = client.get_collection(COL_PRALINE, embedding_function=embed_fn)\n",
    "\n",
    "    print(f\"Indexed RAW:     docs={len(docs)}, chunks={chunks_raw}\")\n",
    "    print(f\"Indexed PRALINE: docs={len(docs)}, chunks={chunks_prl}\")\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"FULL QUESTION DEBUG\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    for q, expected_doc in EVAL:\n",
    "\n",
    "        print(\"\\n-----------------------------------\")\n",
    "        print(f\"Question: {q}\")\n",
    "        print(f\"Expected doc: {expected_doc}\")\n",
    "\n",
    "        print(\"\\nRAW:\")\n",
    "        query_debug(col_raw, q, top_k=5)\n",
    "\n",
    "        print(\"\\nPRALINE:\")\n",
    "        query_debug(col_prl, q, top_k=5)\n",
    "\n",
    "    # Metrics\n",
    "    m_raw = evaluate(col_raw, EVAL, TOP_KS)\n",
    "    m_prl = evaluate(col_prl, EVAL, TOP_KS)\n",
    "\n",
    "    print(\"\\n--- RAW ---\")\n",
    "    for k, v in m_raw.items():\n",
    "        print(k, \":\", v)\n",
    "\n",
    "    print(\"\\n--- PRALINE ---\")\n",
    "    for k, v in m_prl.items():\n",
    "        print(k, \":\", v)\n",
    "\n",
    "    print(\"\\n--- Summary (doc-level) ---\")\n",
    "    print(\"RAW    :\", m_raw)\n",
    "    print(\"PRALINE:\", m_prl)\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"PRALINE REPORTS\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    for doc_id, report in praline_reports.items():\n",
    "        print(f\"\\nDocument: {doc_id}\")\n",
    "        if report is None:\n",
    "            print(\"No report.\")\n",
    "            continue\n",
    "\n",
    "        print(report)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5c4f64",
   "metadata": {},
   "source": [
    "Test Praline on HTML\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8fd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "import feedparser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import trafilatura\n",
    "from tqdm import tqdm\n",
    "from textpraline.cleaner.clean import praline, PralineReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263bd717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS: Le Monde.fr - Actualités et Infos en France et dans le monde\n",
      "entries: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetch + extract + praline: 100%|██████████| 18/18 [00:01<00:00, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "built docs: 18\n",
      "\n",
      "=== PRALINE REPORT SUMMARY (aggregate) ===\n",
      "docs                         18\n",
      "input_len_sum                101032\n",
      "output_len_sum               101056\n",
      "removed_toc_lines            0\n",
      "normalized_extracted_true    18\n",
      "removed_layout_noise_lines   0\n",
      "removed_repeated_lines       0\n",
      "removed_boilerplate_lines    0\n",
      "compression_ratio_out_in     1.0002375484994852\n",
      "\n",
      "====================================================================================================\n",
      "L’ex-prince Andrew arrêté pour des soupçons de « faute professionnelle dans l’exercice de fonctions publiques », nouveau développement de l’affaire Epstein au Royaume-Uni\n",
      "https://www.lemonde.fr/international/article/2026/02/19/affaire-epstein-andrew-mountbatten-windsor-arrete-pour-des-soupcons-de-faute-professionnelle-dans-l-exercice-de-fonctions-publiques-selon-des-medias-britanniques_6667387_3210.html\n",
      "published: Thu, 19 Feb 2026 11:37:32 +0100\n",
      "\n",
      "report: PralineReport(input_len=1992, output_len=1992, removed_toc_lines=0, normalized_extracted=True, removed_layout_noise_lines=0, removed_repeated_lines=0, removed_boilerplate_lines=0)\n",
      "\n",
      "--- RAW (head) ---\n",
      "Andrew Mountbatten Windsor, frère du roi Charles III et prince déchu, a été arrêté, jeudi 19 février, par la police britannique pour des soupçons de « faute professionnelle dans l’exercice de fonctions publiques », selon plusieurs médias. De nouveaux documents semblant montrer que l’ancien prince avait transmis des documents confidentiels à Jeffrey Epstein ont émergé et la police avait déclaré la semaine dernière examiner des plaintes.\n",
      "La police de Thames Valley, qui couvre les zones à l’ouest de Londres, a déclaré jeudi qu’elle avait ouvert une enquête et qu’elle « évaluait » les infomations. La police n’a pas nommé Andrew Mountbatten Windsor, comme le prévoit la loi britannique, mais elle a renvoyé à un communiqué annonçant qu’elle avait arrêté un homme d’une soixantaine d’années. Elle a aussi dit perquisitionner dans deux propriétés du sud et de l’est de l’Angleterre, apparemment en l\n",
      "\n",
      "--- PRALINE (head) ---\n",
      "Andrew Mountbatten Windsor, frère du roi Charles III et prince déchu, a été arrêté, jeudi 19 février, par la police britannique pour des soupçons de « faute professionnelle dans l'exercice de fonctions publiques », selon plusieurs médias. De nouveaux documents semblant montrer que l'ancien prince avait transmis des documents confidentiels à Jeffrey Epstein ont émergé et la police avait déclaré la semaine dernière examiner des plaintes.\n",
      "La police de Thames Valley, qui couvre les zones à l'ouest de Londres, a déclaré jeudi qu'elle avait ouvert une enquête et qu'elle « évaluait » les infomations. La police n'a pas nommé Andrew Mountbatten Windsor, comme le prévoit la loi britannique, mais elle a renvoyé à un communiqué annonçant qu'elle avait arrêté un homme d'une soixantaine d'années. Elle a aussi dit perquisitionner dans deux propriétés du sud et de l'est de l'Angleterre, apparemment en l\n",
      "\n",
      "====================================================================================================\n",
      "Après la mort de Quentin Deranque, les macronistes font le pari électoral du « ni LFI ni RN »\n",
      "https://www.lemonde.fr/politique/article/2026/02/19/apres-la-mort-de-quentin-deranque-les-macronistes-font-le-pari-electoral-du-ni-lfi-ni-rn_6667370_823448.html\n",
      "published: Thu, 19 Feb 2026 10:24:43 +0100\n",
      "\n",
      "report: PralineReport(input_len=1184, output_len=1184, removed_toc_lines=0, normalized_extracted=True, removed_layout_noise_lines=0, removed_repeated_lines=0, removed_boilerplate_lines=0)\n",
      "\n",
      "--- RAW (head) ---\n",
      "La bataille présidentielle les divise, leur rejet de La France insoumise (LFI) pourrait les rassembler. La mort de Quentin Deranque, 23 ans, militant d’extrême droite lynché à Lyon, jeudi 12 février, par des individus soupçonnés d’appartenir au groupuscule antifasciste de la Jeune Garde, proche de LFI, a engendré une condamnation unanime des élus de Renaissance, du MoDem et d’Horizons. Les partis du bloc central mettent en cause la responsabilité du mouvement « insoumis » et de son chef de file, Jean-Luc Mélenchon, les accusant d’entretenir par leur rhétorique conflictuelle un climat propice à la violence politique.\n",
      "« Le refus de la violence physique comme de la violence verbale vaut pour tout le monde, en tout temps, en tout lieu. Voilà peut-être ce qui nous sépare », a tonné, mardi 17 février, le premier ministre, Sébastien Lecornu, à l’Assemblée nationale. Le locataire de Matignon a i\n",
      "\n",
      "--- PRALINE (head) ---\n",
      "La bataille présidentielle les divise, leur rejet de La France insoumise (LFI) pourrait les rassembler. La mort de Quentin Deranque, 23 ans, militant d'extrême droite lynché à Lyon, jeudi 12 février, par des individus soupçonnés d'appartenir au groupuscule antifasciste de la Jeune Garde, proche de LFI, a engendré une condamnation unanime des élus de Renaissance, du MoDem et d'Horizons. Les partis du bloc central mettent en cause la responsabilité du mouvement « insoumis » et de son chef de file, Jean-Luc Mélenchon, les accusant d'entretenir par leur rhétorique conflictuelle un climat propice à la violence politique.\n",
      "« Le refus de la violence physique comme de la violence verbale vaut pour tout le monde, en tout temps, en tout lieu. Voilà peut-être ce qui nous sépare », a tonné, mardi 17 février, le premier ministre, Sébastien Lecornu, à l'Assemblée nationale. Le locataire de Matignon a i\n",
      "\n",
      "====================================================================================================\n",
      "EN DIRECT, tempête Pedro : l’épisode de crues est « loin d’être terminé », selon le ministre de la transition écologique ; quatre départements toujours en vigilance rouge\n",
      "https://www.lemonde.fr/planete/live/2026/02/19/en-direct-tempete-pedro-sebastien-lecornu-promet-une-mobilisation-totale-et-une-indemnisation-au-plus-vite-pour-les-victimes-des-crues-quatre-departements-toujours-en-vigilance-rouge_6667343_3244.html\n",
      "published: Thu, 19 Feb 2026 09:43:16 +0100\n",
      "\n",
      "report: PralineReport(input_len=19104, output_len=19106, removed_toc_lines=0, normalized_extracted=True, removed_layout_noise_lines=0, removed_repeated_lines=0, removed_boilerplate_lines=0)\n",
      "\n",
      "--- RAW (head) ---\n",
      "Quel temps fait-il dans votre ville alors qu’une partie du pays est touchée par la tempête Pedro, après la tempête Nils il y a quelques jours ? Retrouvez notre « Météo du climat ».\n",
      "EN DIRECT, tempête Pedro : l’épisode de crues est « loin d’être terminé », selon le ministre de la transition écologique ; quatre départements toujours en vigilance rouge\n",
      "Quinze départements de la façade ouest sont, par ailleurs, en vigilance orange crues ce matin, selon le dernier bulletin de Météo-France.\n",
      "Posez votre question à la rédaction :\n",
      "« L’arrêt des pluies ne signifie pas l’arrêt des crues », prévient la directrice de Vigicrues\n",
      "Après trente-cinq jours de pluie consécutifs, plus longue période de précipitations depuis le début des mesures en 1959, le passage de Pedro, « tempête hivernale non exceptionnelle », a incité Météo-France à la prudence, ses « fortes rafales de vent intervenant sur des sols trè\n",
      "\n",
      "--- PRALINE (head) ---\n",
      "Quel temps fait-il dans votre ville alors qu'une partie du pays est touchée par la tempête Pedro, après la tempête Nils il y a quelques jours ? Retrouvez notre « Météo du climat ».\n",
      "EN DIRECT, tempête Pedro : l'épisode de crues est « loin d'être terminé », selon le ministre de la transition écologique ; quatre départements toujours en vigilance rouge\n",
      "Quinze départements de la façade ouest sont, par ailleurs, en vigilance orange crues ce matin, selon le dernier bulletin de Météo-France.\n",
      "Posez votre question à la rédaction :\n",
      "« L'arrêt des pluies ne signifie pas l'arrêt des crues », prévient la directrice de Vigicrues\n",
      "Après trente-cinq jours de pluie consécutifs, plus longue période de précipitations depuis le début des mesures en 1959, le passage de Pedro, « tempête hivernale non exceptionnelle », a incité Météo-France à la prudence, ses « fortes rafales de vent intervenant sur des sols trè\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RSS_URL = \"https://www.lemonde.fr/rss/une.xml\"\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": \"Mozilla/5.0 (Notebook; +https://example.com)\"})\n",
    "\n",
    "def fetch_html(url: str, timeout: int = 20) -> str:\n",
    "    r = session.get(url, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "def extract_text_raw(html: str) -> str:\n",
    "    \"\"\"\n",
    "    RAW = extraction main-content (trafilatura) si possible,\n",
    "    sinon fallback BeautifulSoup.\n",
    "    \"\"\"\n",
    "    main = trafilatura.extract(\n",
    "        html,\n",
    "        include_comments=False,\n",
    "        include_links=False,\n",
    "        include_tables=False,\n",
    "        favor_recall=False,\n",
    "    )\n",
    "    if main and main.strip():\n",
    "        return main.strip()\n",
    "\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
    "        tag.decompose()\n",
    "    txt = soup.get_text(\"\\n\")\n",
    "    txt = re.sub(r\"\\n{3,}\", \"\\n\\n\", txt)\n",
    "    txt = re.sub(r\"[ \\t]{2,}\", \" \", txt)\n",
    "    return txt.strip()\n",
    "\n",
    "def make_doc_id(url: str) -> str:\n",
    "    # stable-ish id, short\n",
    "    return re.sub(r\"\\W+\", \"_\", url).strip(\"_\")[-60:]\n",
    "\n",
    "# ---- 1) Read RSS\n",
    "feed = feedparser.parse(RSS_URL)\n",
    "entries = list(feed.entries)\n",
    "print(\"RSS:\", getattr(feed.feed, \"title\", \"\"))\n",
    "print(\"entries:\", len(entries))\n",
    "\n",
    "N = 20  # augmente si tu veux\n",
    "entries = entries[:N]\n",
    "\n",
    "docs: List[Dict] = []\n",
    "for e in tqdm(entries, desc=\"Fetch + extract + praline\"):\n",
    "    url = e.link\n",
    "    title = getattr(e, \"title\", \"\").strip()\n",
    "    published = getattr(e, \"published\", \"\")\n",
    "\n",
    "    try:\n",
    "        html = fetch_html(url)\n",
    "        raw_text = extract_text_raw(html)\n",
    "        praline_text, rep = praline(raw_text, debug=True, normalize_extracted=True, drop_repeated_lines=\"off\", drop_layout_noise=\"off\")\n",
    "    except Exception as ex:\n",
    "        print(\"skip:\", url, ex)\n",
    "        continue\n",
    "\n",
    "    docs.append({\n",
    "        \"doc_id\": make_doc_id(url),\n",
    "        \"url\": url,\n",
    "        \"title\": title,\n",
    "        \"published\": published,\n",
    "        \"raw\": raw_text,\n",
    "        \"praline\": praline_text,\n",
    "        \"report\": rep,\n",
    "    })\n",
    "\n",
    "print(\"built docs:\", len(docs))\n",
    "\n",
    "# ---- 2) Summary table (light, lisible)\n",
    "def summarize_reports(docs: List[Dict]) -> None:\n",
    "    total_in = sum(d[\"report\"].input_len for d in docs)\n",
    "    total_out = sum(d[\"report\"].output_len for d in docs)\n",
    "    totals = {\n",
    "        \"docs\": len(docs),\n",
    "        \"input_len_sum\": total_in,\n",
    "        \"output_len_sum\": total_out,\n",
    "        \"removed_toc_lines\": sum(d[\"report\"].removed_toc_lines for d in docs),\n",
    "        \"normalized_extracted_true\": sum(1 for d in docs if d[\"report\"].normalized_extracted),\n",
    "        \"removed_layout_noise_lines\": sum(d[\"report\"].removed_layout_noise_lines for d in docs),\n",
    "        \"removed_repeated_lines\": sum(d[\"report\"].removed_repeated_lines for d in docs),\n",
    "        \"removed_boilerplate_lines\": sum(d[\"report\"].removed_boilerplate_lines for d in docs),\n",
    "        \"compression_ratio_out_in\": (total_out / total_in) if total_in else 0.0,\n",
    "    }\n",
    "    print(\"\\n=== PRALINE REPORT SUMMARY (aggregate) ===\")\n",
    "    for k, v in totals.items():\n",
    "        print(f\"{k:28} {v}\")\n",
    "\n",
    "summarize_reports(docs)\n",
    "\n",
    "# ---- 3) Inspect a few examples side-by-side\n",
    "def preview(i: int, n: int = 900):\n",
    "    d = docs[i]\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(d[\"title\"])\n",
    "    print(d[\"url\"])\n",
    "    print(\"published:\", d[\"published\"])\n",
    "    print(\"\\nreport:\", d[\"report\"])\n",
    "    print(\"\\n--- RAW (head) ---\")\n",
    "    print(d[\"raw\"][:n])\n",
    "    print(\"\\n--- PRALINE (head) ---\")\n",
    "    print(d[\"praline\"][:n])\n",
    "\n",
    "for i in range(min(3, len(docs))):\n",
    "    preview(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9189477d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1303.52it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed RAW chunks    : 138\n",
      "Indexed PRALINE chunks: 138\n",
      "\n",
      "RAW metrics   : {'recall@1': 0.8888888888888888, 'recall@5': 1.0, 'recall@10': 1.0, 'mrr': 0.9185185185185184, 'n_queries': 18}\n",
      "PRALINE metrics: {'recall@1': 0.8333333333333334, 'recall@5': 1.0, 'recall@10': 1.0, 'mrr': 0.898148148148148, 'n_queries': 18}\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Q: L’ex-prince Andrew arrêté pour des soupçons de « faute professionnelle dans l’exercice de fonctions publiques », nouveau développement de l’affaire Epstein au Royaume-Uni\n",
      "Expected doc: ns_publiques_selon_des_medias_britanniques_6667387_3210_html\n",
      "\n",
      "RAW:\n",
      "1. dist=0.4993 doc_id=ns_publiques_selon_des_medias_britanniques_6667387_3210_html chunk=0\n",
      "    Andrew Mountbatten Windsor, frère du roi Charles III et prince déchu, a été arrêté, jeudi 19 février, par la police britannique pour des soupçons de « faute pro ...\n",
      "2. dist=0.5415 doc_id=ns_publiques_selon_des_medias_britanniques_6667387_3210_html chunk=2\n",
      "    e commerce international, fonction qu’il a occupée de 2001 à 2011. Ces documents sont venus ajouter aux soupçons qui planaient déjà sur Andrew à la suite des ac ...\n",
      "3. dist=0.5781 doc_id=etuite_pour_sa_declaration_de_loi_martiale_6667395_3210_html chunk=1\n",
      "    vile anglaise, qui a vu le roi Charles Ier (1600-1649) donner la troupe pour dissoudre le Parlement. « Il fut reconnu coupable de trahison et exécuté, la cour r ...\n",
      "4. dist=0.6127 doc_id=occuper_de_la_situation_qu_il_suit_de_pres_6667365_3224_html chunk=15\n",
      "    e de ses membres » et le « silence complice d’une partie de la gauche qui refuse de condamner ». « Si M. Arnault avait un peu d’honneur, avec deux assistants pa ...\n",
      "5. dist=0.6175 doc_id=s_font_le_pari_electoral_du_ni_lfi_ni_rn_6667370_823448_html chunk=1\n",
      "    a tonné, mardi 17 février, le premier ministre, Sébastien Lecornu, à l’Assemblée nationale. Le locataire de Matignon a intimé à LFI de « faire le ménage » dans  ...\n",
      "\n",
      "PRALINE:\n",
      "1. dist=0.5084 doc_id=ns_publiques_selon_des_medias_britanniques_6667387_3210_html chunk=0\n",
      "    Andrew Mountbatten Windsor, frère du roi Charles III et prince déchu, a été arrêté, jeudi 19 février, par la police britannique pour des soupçons de « faute pro ...\n",
      "2. dist=0.5667 doc_id=ns_publiques_selon_des_medias_britanniques_6667387_3210_html chunk=2\n",
      "    e commerce international, fonction qu'il a occupée de 2001 à 2011. Ces documents sont venus ajouter aux soupçons qui planaient déjà sur Andrew à la suite des ac ...\n",
      "3. dist=0.5834 doc_id=etuite_pour_sa_declaration_de_loi_martiale_6667395_3210_html chunk=1\n",
      "    vile anglaise, qui a vu le roi Charles Ier (1600-1649) donner la troupe pour dissoudre le Parlement. « Il fut reconnu coupable de trahison et exécuté, la cour r ...\n",
      "4. dist=0.6204 doc_id=occuper_de_la_situation_qu_il_suit_de_pres_6667365_3224_html chunk=15\n",
      "    ertain nombre de ses membres » et le « silence complice d'une partie de la gauche qui refuse de condamner ». « Si M. Arnault avait un peu d'honneur, avec deux a ...\n",
      "5. dist=0.6207 doc_id=s_font_le_pari_electoral_du_ni_lfi_ni_rn_6667370_823448_html chunk=1\n",
      "    a tonné, mardi 17 février, le premier ministre, Sébastien Lecornu, à l'Assemblée nationale. Le locataire de Matignon a intimé à LFI de « faire le ménage » dans  ...\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Q: Après la mort de Quentin Deranque, les macronistes font le pari électoral du « ni LFI ni RN »\n",
      "Expected doc: s_font_le_pari_electoral_du_ni_lfi_ni_rn_6667370_823448_html\n",
      "\n",
      "RAW:\n",
      "1. dist=0.2115 doc_id=occuper_de_la_situation_qu_il_suit_de_pres_6667365_3224_html chunk=14\n",
      "    ussi parce que face à l’extrême droite, je me bats pour l’union à gauche ». Après la mort de Quentin Deranque, les macronistes font le pari électoral du « ni LF ...\n",
      "2. dist=0.4381 doc_id=occuper_de_la_situation_qu_il_suit_de_pres_6667365_3224_html chunk=13\n",
      "     Quentin Deranque. Ce drame a révélé le haut niveau de violence politique qui s’installe dans notre pays », a-t-elle écrit. La candidate à la primaire de la gau ...\n",
      "3. dist=0.4740 doc_id=occuper_de_la_situation_qu_il_suit_de_pres_6667365_3224_html chunk=1\n",
      "    vait en République « pas de place pour les mouvements qui adoptent et légitiment la violence », appelant les « extrêmes » à « faire le ménage » dans leurs rangs ...\n",
      "4. dist=0.4840 doc_id=_un_parti_populiste_aux_accents_trumpistes_6667325_3210_html chunk=1\n",
      "    ional, principalement implantée dans les régions rurales. Mais depuis le mois de janvier, les sondages placent, pour la première fois dans l’histoire politique  ...\n",
      "5. dist=0.4842 doc_id=occuper_de_la_situation_qu_il_suit_de_pres_6667365_3224_html chunk=7\n",
      "    st-elle avérée ? Bonjour François, Selon les informations de Mediapart, Quentin Deranque a participé en mai 2025 au défilé du Comité du 9 mai à Paris, rassemble ...\n",
      "\n",
      "PRALINE:\n",
      "1. dist=0.2036 doc_id=occuper_de_la_situation_qu_il_suit_de_pres_6667365_3224_html chunk=14\n",
      "    LFI, c'est aussi parce que face à l'extrême droite, je me bats pour l'union à gauche ». Après la mort de Quentin Deranque, les macronistes font le pari électora ...\n",
      "2. dist=0.4329 doc_id=occuper_de_la_situation_qu_il_suit_de_pres_6667365_3224_html chunk=13\n",
      "    meurtre de Quentin Deranque. Ce drame a révélé le haut niveau de violence politique qui s'installe dans notre pays », a-t-elle écrit. La candidate à la primaire ...\n",
      "3. dist=0.4745 doc_id=occuper_de_la_situation_qu_il_suit_de_pres_6667365_3224_html chunk=1\n",
      "    vait en République « pas de place pour les mouvements qui adoptent et légitiment la violence », appelant les « extrêmes » à « faire le ménage » dans leurs rangs ...\n",
      "4. dist=0.4778 doc_id=occuper_de_la_situation_qu_il_suit_de_pres_6667365_3224_html chunk=7\n",
      "    du 9 mai est-elle avérée ? Bonjour François, Selon les informations de Mediapart, Quentin Deranque a participé en mai 2025 au défilé du Comité du 9 mai à Paris, ...\n",
      "5. dist=0.4845 doc_id=_un_parti_populiste_aux_accents_trumpistes_6667325_3210_html chunk=1\n",
      "    ional, principalement implantée dans les régions rurales. Mais depuis le mois de janvier, les sondages placent, pour la première fois dans l'histoire politique  ...\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "Q: EN DIRECT, tempête Pedro : l’épisode de crues est « loin d’être terminé », selon le ministre de la transition écologique ; quatre départements toujours en vigilance rouge\n",
      "Expected doc: e_departements_toujours_en_vigilance_rouge_6667343_3244_html\n",
      "\n",
      "RAW:\n",
      "1. dist=0.2954 doc_id=e_departements_toujours_en_vigilance_rouge_6667343_3244_html chunk=0\n",
      "    Quel temps fait-il dans votre ville alors qu’une partie du pays est touchée par la tempête Pedro, après la tempête Nils il y a quelques jours ? Retrouvez notre  ...\n",
      "2. dist=0.3419 doc_id=e_departements_toujours_en_vigilance_rouge_6667343_3244_html chunk=7\n",
      "    « loin d’être terminé », selon le ministre de la transition écologique L’épisode d’intempéries et de crues qui touche la France est « loin d’être terminé », a e ...\n",
      "3. dist=0.4715 doc_id=e_departements_toujours_en_vigilance_rouge_6667343_3244_html chunk=15\n",
      "     vendredi et les quatre départements des Alpes sont en risque d’avalanche, tandis que l’ensemble du littoral atlantique reste en vigilance vagues-submersion. «  ...\n",
      "4. dist=0.4904 doc_id=e_departements_toujours_en_vigilance_rouge_6667343_3244_html chunk=9\n",
      "    e Bordeaux avec des limitations de vitesse ou de parcours, ainsi que des suppressions de TVG InOui, Ouigo et les trains Intercités. La SNCF prévenait également  ...\n",
      "5. dist=0.5458 doc_id=e_departements_toujours_en_vigilance_rouge_6667343_3244_html chunk=10\n",
      "    ème épisode qui arrive très proche du premier va probablement avoir des conséquences dans la vie des habitants de l’ouest de notre pays », a averti M. Tabarot.  ...\n",
      "\n",
      "PRALINE:\n",
      "1. dist=0.3004 doc_id=e_departements_toujours_en_vigilance_rouge_6667343_3244_html chunk=0\n",
      "    Quel temps fait-il dans votre ville alors qu'une partie du pays est touchée par la tempête Pedro, après la tempête Nils il y a quelques jours ? Retrouvez notre  ...\n",
      "2. dist=0.3429 doc_id=e_departements_toujours_en_vigilance_rouge_6667343_3244_html chunk=7\n",
      "    t « loin d'être terminé », selon le ministre de la transition écologique L'épisode d'intempéries et de crues qui touche la France est « loin d'être terminé », a ...\n",
      "3. dist=0.4800 doc_id=e_departements_toujours_en_vigilance_rouge_6667343_3244_html chunk=15\n",
      "    es vendredi et les quatre départements des Alpes sont en risque d'avalanche, tandis que l'ensemble du littoral atlantique reste en vigilance vagues-submersion.  ...\n",
      "4. dist=0.4992 doc_id=e_departements_toujours_en_vigilance_rouge_6667343_3244_html chunk=9\n",
      "     de Bordeaux avec des limitations de vitesse ou de parcours, ainsi que des suppressions de TVG InOui, Ouigo et les trains Intercités. La SNCF prévenait égalemen ...\n",
      "5. dist=0.5506 doc_id=e_departements_toujours_en_vigilance_rouge_6667343_3244_html chunk=10\n",
      "    xième épisode qui arrive très proche du premier va probablement avoir des conséquences dans la vie des habitants de l'ouest de notre pays », a averti M. Tabarot ...\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "# --------- Embedding\n",
    "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "embed_fn = SentenceTransformerEmbeddingFunction(model_name=EMBED_MODEL)\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "def rebuild_collection(name: str):\n",
    "    try:\n",
    "        client.delete_collection(name)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return client.get_or_create_collection(name=name, embedding_function=embed_fn)\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 900, overlap: int = 120) -> List[str]:\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()\n",
    "    if not text:\n",
    "        return []\n",
    "    out = []\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        j = min(len(text), i + chunk_size)\n",
    "        out.append(text[i:j])\n",
    "        i = max(i + chunk_size - overlap, i + 1)\n",
    "    return out\n",
    "\n",
    "def index_docs(col, docs: List[Dict], field: str) -> int:\n",
    "    ids, texts, metas = [], [], []\n",
    "    total = 0\n",
    "    for d in docs:\n",
    "        chunks = chunk_text(d[field])\n",
    "        for k, ch in enumerate(chunks):\n",
    "            ids.append(f'{d[\"doc_id\"]}__{field}__{k}')\n",
    "            texts.append(ch)\n",
    "            metas.append({\n",
    "                \"doc_id\": d[\"doc_id\"],\n",
    "                \"url\": d[\"url\"],\n",
    "                \"title\": d[\"title\"],\n",
    "                \"chunk_idx\": k,\n",
    "                \"field\": field,\n",
    "            })\n",
    "        total += len(chunks)\n",
    "    if ids:\n",
    "        col.add(ids=ids, documents=texts, metadatas=metas)\n",
    "    return total\n",
    "\n",
    "raw_col = rebuild_collection(\"lemonde_raw\")\n",
    "pra_col = rebuild_collection(\"lemonde_praline\")\n",
    "\n",
    "raw_chunks = index_docs(raw_col, docs, \"raw\")\n",
    "pra_chunks = index_docs(pra_col, docs, \"praline\")\n",
    "\n",
    "print(\"Indexed RAW chunks    :\", raw_chunks)\n",
    "print(\"Indexed PRALINE chunks:\", pra_chunks)\n",
    "\n",
    "# --------- Retrieval eval (doc-level): queries = titles (baseline)\n",
    "eval_set = [{\"q\": d[\"title\"], \"expected_doc\": d[\"doc_id\"]} for d in docs if d[\"title\"]]\n",
    "\n",
    "def top_docs(col, query: str, top_k: int = 10) -> List[str]:\n",
    "    res = col.query(query_texts=[query], n_results=top_k, include=[\"metadatas\"])\n",
    "    seen, ranked = set(), []\n",
    "    for md in res[\"metadatas\"][0]:\n",
    "        doc_id = md.get(\"doc_id\")\n",
    "        if doc_id and doc_id not in seen:\n",
    "            seen.add(doc_id)\n",
    "            ranked.append(doc_id)\n",
    "    return ranked\n",
    "\n",
    "def compute_metrics(col, eval_set, ks=(1,5,10)) -> Dict[str, float]:\n",
    "    recalls = {k: 0 for k in ks}\n",
    "    rr_sum = 0.0\n",
    "    n = 0\n",
    "    for ex in eval_set:\n",
    "        q, gold = ex[\"q\"], ex[\"expected_doc\"]\n",
    "        ranked = top_docs(col, q, top_k=max(ks))\n",
    "        n += 1\n",
    "        for k in ks:\n",
    "            if gold in ranked[:k]:\n",
    "                recalls[k] += 1\n",
    "        if gold in ranked:\n",
    "            rr_sum += 1.0 / (ranked.index(gold) + 1)\n",
    "    out = {f\"recall@{k}\": recalls[k] / n for k in ks}\n",
    "    out[\"mrr\"] = rr_sum / n\n",
    "    out[\"n_queries\"] = n\n",
    "    return out\n",
    "\n",
    "raw_metrics = compute_metrics(raw_col, eval_set)\n",
    "pra_metrics = compute_metrics(pra_col, eval_set)\n",
    "\n",
    "print(\"\\nRAW metrics   :\", raw_metrics)\n",
    "print(\"PRALINE metrics:\", pra_metrics)\n",
    "\n",
    "# --------- Debug few queries side-by-side\n",
    "def debug_query(q: str, expected_doc: str, top_k: int = 5):\n",
    "    print(\"\\n\" + \"-\"*90)\n",
    "    print(\"Q:\", q)\n",
    "    print(\"Expected doc:\", expected_doc)\n",
    "\n",
    "    for label, col in [(\"RAW\", raw_col), (\"PRALINE\", pra_col)]:\n",
    "        res = col.query(query_texts=[q], n_results=top_k, include=[\"metadatas\",\"distances\",\"documents\"])\n",
    "        print(f\"\\n{label}:\")\n",
    "        for i, (md, dist, doc) in enumerate(zip(res[\"metadatas\"][0], res[\"distances\"][0], res[\"documents\"][0]), start=1):\n",
    "            print(f\"{i}. dist={dist:.4f} doc_id={md['doc_id']} chunk={md['chunk_idx']}\")\n",
    "            print(\"   \", doc[:160].replace(\"\\n\", \" \") + \" ...\")\n",
    "\n",
    "for ex in eval_set[:3]:\n",
    "    debug_query(ex[\"q\"], ex[\"expected_doc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40e788ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://www.lemonde.fr/international/article/2026/02/19/affaire-epstein-andrew-mountbatten-windsor-arrete-pour-des-soupcons-de-faute-professionnelle-dans-l-exercice-de-fonctions-publiques-selon-des-medias-britanniques_6667387_3210.html\n",
      "delta chars: 0\n",
      "raw lines: 5 praline lines: 5 removed lines: 5\n",
      "\n",
      "--- sample removed lines ---\n",
      "- Andrew Mountbatten Windsor, frère du roi Charles III et prince déchu, a été arrêté, jeudi 19 février, par la police britannique pour des soupçons de « faute professionnelle dans l’\n",
      "- La police de Thames Valley, qui couvre les zones à l’ouest de Londres, a déclaré jeudi qu’elle avait ouvert une enquête et qu’elle « évaluait » les infomations. La police n’a pas n\n",
      "- Cette dernière a eu lieu dans la résidence royale de Sandringham, dans le Norfolk, et s’est déroulée le jour du 66e anniversaire de M. Mountbatten Windsor. C’est la première fois d\n",
      "- Selon un courriel daté du 24 décembre 2010 et adressé à Jeffrey Epstein, issu des dossiers publiés par le ministère de la justice américain, l’ancien prince a transmis « un rapport\n",
      "- Ces documents sont venus ajouter aux soupçons qui planaient déjà sur Andrew à la suite des accusations d’agressions sexuelles de Virginia Giuffre, principale témoin à charge du dos\n"
     ]
    }
   ],
   "source": [
    "# trouve le doc le plus \"compressé\"\n",
    "d = max(docs, key=lambda x: x[\"report\"].input_len - x[\"report\"].output_len)\n",
    "\n",
    "raw_lines = [ln.strip() for ln in d[\"raw\"].splitlines() if ln.strip()]\n",
    "pra_lines = [ln.strip() for ln in d[\"praline\"].splitlines() if ln.strip()]\n",
    "\n",
    "removed = [ln for ln in raw_lines if ln not in set(pra_lines)]\n",
    "\n",
    "print(\"URL:\", d[\"url\"])\n",
    "print(\"delta chars:\", d[\"report\"].input_len - d[\"report\"].output_len)\n",
    "print(\"raw lines:\", len(raw_lines), \"praline lines:\", len(pra_lines), \"removed lines:\", len(removed))\n",
    "print(\"\\n--- sample removed lines ---\")\n",
    "for ln in removed[:30]:\n",
    "    print(\"-\", ln[:180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833a0e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "d = max(docs, key=lambda x: x[\"report\"].input_len - x[\"report\"].output_len)\n",
    "\n",
    "def norm_line(ln: str) -> str:\n",
    "    return re.sub(r\"[ \\t]+\", \" \", ln.strip())\n",
    "\n",
    "raw_norm = [norm_line(ln) for ln in d[\"raw\"].splitlines() if norm_line(ln)]\n",
    "c = Counter(raw_norm)\n",
    "\n",
    "# lignes \"suspectes\" : celles qui ont >=5 occurrences\n",
    "suspects = [ln for ln, n in c.items() if n >= 5]\n",
    "suspects[:30], len(suspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01bb27cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_web\n",
      "ocr_like\n"
     ]
    }
   ],
   "source": [
    "from textpraline.cleaner import clean\n",
    "\n",
    "print(clean.detect_text_profile(raw_text))\n",
    "path = Path(CORPUS_DIR)\n",
    "for doc_id, text in load_pdf_corpus(path):\n",
    "    doc_text = text\n",
    "    break \n",
    "print(clean.detect_text_profile(doc_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textpraline-BxvUXBda-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
